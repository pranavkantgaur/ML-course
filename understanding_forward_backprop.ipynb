{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "understanding-forward-backprop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhQDwqDgfNSE7ggKMeWsdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavkantgaur/ML-course/blob/main/understanding_forward_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "056ww1eV2IHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me2hwpK0qgJK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "a2a28f0b-3874-4680-952d-21e79394e9a7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35bae8e2b464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate s = 0.9a + 0.9b dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mid_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# Generate s = 0.9a + 0.9b dataset\n",
        "a = np.arange(1, 101)\n",
        "b = np.arange(100, 201)\n",
        "id_arr = np.arange(100)\n",
        "np.random.shuffle(id_arr)\n",
        "print(id_arr)\n",
        "print(\"a: \", a)\n",
        "print(\"b: \", b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = open('data_file.txt', 'w')\n",
        "for i in id_arr:\n",
        "  data_file.write('{}, {}, {:.2f}\\n'.format(a[i], b[i], 0.9 * a[i] + 0.9 * b[i]))\n",
        "data_file.close()\n",
        "'''\n",
        "# Try to fit a NN implementing forward and backprop in numpy from scratch\n",
        "a = w * x + b\n",
        "a = w * a + b\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-xsPZvbU17Xj",
        "outputId": "1f6d7250-f657-46f2-aa48-2d01e8ec0470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Try to fit a NN implementing forward and backprop in numpy from scratch\\na = w * x + b\\na = w * a + b\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Write a neural network which given a, b predicts 0.9a + 0.9b\n",
        "'''\n",
        "1. Define nodes: INput , hidden, output\n",
        "2. Define layers using nodes\n",
        "3. Define forward propogation\n",
        "4. Define backpropogation\n",
        "5. Define optimization model\n",
        "6. For each epoch:(for n epochs, where n = len(data) / batch_size):\n",
        "   6.0 . Shuffle training data: ind-array update\n",
        "   For each batch: \n",
        "    6.1. Load train data: [ind: ind + batch_size]\n",
        "    6.2: For each sample:\n",
        "        6.2.0. Forward propogate\n",
        "        6.2.1. Calculate loss for each sample\n",
        "        6.2.2. Backprogate: Calculate gradients and update weights\n",
        "    6.3. Calculate average loss\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ci50Ssk34CmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(object):\n",
        "  def __init__(self, type, activation_function):\n",
        "    pass"
      ],
      "metadata": {
        "id": "uuWGhkDyCEwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HiddenNode(object):\n",
        "  pass"
      ],
      "metadata": {
        "id": "yVs3gjnE_oPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputNode(object):\n",
        "  pass"
      ],
      "metadata": {
        "id": "kZQ8L1wGCUT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ELPDCbKaH8yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinkMatrix():\n",
        "  def __init__(self, row, col, def=None):\n",
        "    if def = None:\n",
        "      # Random init\n",
        "      self.matrix = [[] for row in range(rows)]\n",
        "      for row in range(rows):\n",
        "        self.matrix[row] = [np.random.uniform(min = 0.0, max = 1.0) for col in range(columns)]\n",
        "      return self.matrix        \n"
      ],
      "metadata": {
        "id": "RbOEJewRH8G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer():\n",
        "  def __init__(self, node_type, n_nodes, activation=None):\n",
        "    self.node_type = node_type\n",
        "    if node_type == 'input':\n",
        "      self.nodes = [InputNode(activation) for node_id in range(n_nodes)]\n",
        "    if node_type == 'hidden':\n",
        "      self.nodes = [HiddenNode(activation) for node_id in range(n_nodes)]\n",
        "    if node_type == 'output':\n",
        "      self.nodes = [OutputNode(activation) for node_id in range(n_nodes)]  \n",
        "  def connect(self, next_layer):\n",
        "    n_rows = len(self.nodes)              \n",
        "    n_cols = len(next_layer.nodes)\n",
        "    self.weight_mat = LinkMatrix(n_rows, n_cols)\n",
        "\n",
        "  def forward(self, fwd_data):\n",
        "    if self.node_type == 'input':\n",
        "      self.input_to_hidden()\n",
        "    if self.node_type == 'hidden':\n",
        "      self.hidden_to_hidden()\n",
        "    self.hidden_to_output()\n",
        "  \n",
        "  def backward(self, gradients):"
      ],
      "metadata": {
        "id": "lyZ2dfb7CaN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer_list.append(node)\n",
        "inp_layer = Layer('input', 2)\n",
        "hidden_layer_1 = Layer('hidden', 3, 'relu')\n",
        "inp_layer.connect(hidden_layer_1)\n",
        " \n",
        "hidden_layer_2 = Layer('hidden', 3, 'relu')\n",
        "hidden_layer_1.connect(hidden_layer_2)\n",
        "    \n",
        "output_layer = Layer('output', 1, 'sigmoid')\n",
        "hidden_layer2.connect(output_layer)"
      ],
      "metadata": {
        "id": "2hRSRN6FFKBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP():  \n",
        "  self.input_layer_list = []\n",
        "  self.hidden_layer_list = []\n",
        "  self.output_layer_list = []\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def model():\n",
        "    self.weight_matrix = \n",
        "    self.last_layer = None\n",
        "    \n",
        "\n",
        "  def append_layer(layer_type = 'hidden'):\n",
        "    new_layer = Layer('hidden', 3, 'relu')\n",
        "    self.last_layer.connect(new_layer)\n",
        "  \n",
        "  def fit(train_x, train_y):\n",
        "    n_train = 1000000\n",
        "    train_ids = arange(n_train) # [0, 1, .... 99999]\n",
        "    n_epochs = 1000\n",
        "    batch_size = 100\n",
        "    n_batches = n_train // batch_size\n",
        "    hidden_layers = [hidden_layer_1, hidden_layer_2]\n",
        "    for epoch in range(n_epochs):\n",
        "      train_ids = util.shuffle(train_ids)      \n",
        "      for batch_id in range(n_batches):\n",
        "        train_x, train_y = get_data([batch_id:batch_id + batch_size], train_ids)\n",
        "        inp_out = \n",
        "        hidden_1_out = \n",
        "  "
      ],
      "metadata": {
        "id": "Lpbrq9r7Hy0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "6. For each epoch:(for n epochs, where n = len(data) / batch_size):\n",
        "   6.0 . Shuffle training data: ind-array update\n",
        "   For each batch: \n",
        "    6.1. Load train data: [ind: ind + batch_size]\n",
        "    6.2: For each sample:\n",
        "        6.2.0. Forward propogate\n",
        "        6.2.1. Calculate loss for each sample\n",
        "        6.2.2. Backprogate: Calculate gradients and update weights\n",
        "    6.3. Calculate average loss\n",
        "'''\n",
        "n_train = 1000000\n",
        "train_ids = arange(n_train) # [0, 1, .... 99999]\n",
        "n_epochs = 1000\n",
        "batch_size = 100\n",
        "n_batches = n_train // batch_size\n",
        "hidden_layers = [hidden_layer_1, hidden_layer_2]\n",
        "for epoch in range(n_epochs):\n",
        "  train_ids = util.shuffle(train_ids)      \n",
        "  for batch_id in range(n_batches):\n",
        "    train_x, train_y = get_data([batch_id:batch_id + batch_size], train_ids)\n",
        "    inp_out = \n",
        "    hidden_1_out = \n",
        "    "
      ],
      "metadata": {
        "id": "TMr6HrW5DY2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}