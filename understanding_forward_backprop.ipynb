{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "understanding-forward-backprop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrlmNZZfMVsqYcjsr6Jr4V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavkantgaur/ML-course/blob/main/understanding_forward_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "056ww1eV2IHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me2hwpK0qgJK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "a2a28f0b-3874-4680-952d-21e79394e9a7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35bae8e2b464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate s = 0.9a + 0.9b dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mid_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# Generate s = 0.9a + 0.9b dataset\n",
        "a = np.arange(1, 101)\n",
        "b = np.arange(100, 201)\n",
        "id_arr = np.arange(100)\n",
        "np.random.shuffle(id_arr)\n",
        "print(id_arr)\n",
        "print(\"a: \", a)\n",
        "print(\"b: \", b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = open('data_file.txt', 'w')\n",
        "for i in id_arr:\n",
        "  data_file.write('{}, {}, {:.2f}\\n'.format(a[i], b[i], 0.9 * a[i] + 0.9 * b[i]))\n",
        "data_file.close()\n",
        "'''\n",
        "# Try to fit a NN implementing forward and backprop in numpy from scratch\n",
        "a = w * x + b\n",
        "a = w * a + b\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-xsPZvbU17Xj",
        "outputId": "1f6d7250-f657-46f2-aa48-2d01e8ec0470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Try to fit a NN implementing forward and backprop in numpy from scratch\\na = w * x + b\\na = w * a + b\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Write a neural network which given a, b predicts 0.9a + 0.9b\n",
        "'''\n",
        "1. Define nodes: INput , hidden, output\n",
        "2. Define layers using nodes\n",
        "3. Define forward propogation\n",
        "4. Define backpropogation\n",
        "5. Define optimization model\n",
        "6. For each epoch:(for n epochs, where n = len(data) / batch_size):\n",
        "   6.0 . Shuffle training data: ind-array update\n",
        "   For each batch: \n",
        "    6.1. Load train data: [ind: ind + batch_size]\n",
        "    6.2: For each sample:\n",
        "        6.2.0. Forward propogate\n",
        "        6.2.1. Calculate loss for each sample\n",
        "        6.2.2. Backprogate: Calculate gradients and update weights\n",
        "    6.3. Calculate average loss\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ci50Ssk34CmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(object):\n",
        "  def __init__(self, type, activation_function):\n",
        "    pass"
      ],
      "metadata": {
        "id": "uuWGhkDyCEwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HiddenNode(object):\n",
        "  pass"
      ],
      "metadata": {
        "id": "yVs3gjnE_oPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputNode(object):\n",
        "  pass"
      ],
      "metadata": {
        "id": "kZQ8L1wGCUT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ELPDCbKaH8yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinkMatrix():\n",
        "  def __init__(self, row, col, def=None):\n",
        "    if def = None:\n",
        "      # Random init\n",
        "      self.matrix = [[] for row in range(rows)]\n",
        "      for row in range(rows):\n",
        "        self.matrix[row] = [np.random.uniform(min = 0.0, max = 1.0) for col in range(columns)]\n",
        "      return self.matrix        \n"
      ],
      "metadata": {
        "id": "RbOEJewRH8G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer():\n",
        "  def __init__(self, node_type, n_nodes, activation=None):\n",
        "    self.node_type = node_type\n",
        "    if node_type == 'input':\n",
        "      self.nodes = [InputNode(activation) for node_id in range(n_nodes)]\n",
        "    if node_type == 'hidden':\n",
        "      self.nodes = [HiddenNode(activation) for node_id in range(n_nodes)]\n",
        "    if node_type == 'output':\n",
        "      self.nodes = [OutputNode(activation) for node_id in range(n_nodes)]  \n",
        "  def connect(self, next_layer):\n",
        "    n_rows = len(self.nodes)              \n",
        "    n_cols = len(next_layer.nodes)\n",
        "    self.weight_mat = LinkMatrix(n_rows, n_cols)\n",
        "\n",
        "  def forward(self, fwd_data):\n",
        "    if self.node_type == 'input':\n",
        "      self.input_to_hidden()\n",
        "    if self.node_type == 'hidden':\n",
        "      self.hidden_to_hidden()\n",
        "    self.hidden_to_output()\n",
        "  \n",
        "  def backward(self, gradients):"
      ],
      "metadata": {
        "id": "lyZ2dfb7CaN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer_list.append(node)\n",
        "inp_layer = Layer('input', 2)\n",
        "hidden_layer_1 = Layer('hidden', 3, 'relu')\n",
        "inp_layer.connect(hidden_layer_1)\n",
        " \n",
        "hidden_layer_2 = Layer('hidden', 3, 'relu')\n",
        "hidden_layer_1.connect(hidden_layer_2)\n",
        "    \n",
        "output_layer = Layer('output', 1, 'sigmoid')\n",
        "hidden_layer2.connect(output_layer)"
      ],
      "metadata": {
        "id": "2hRSRN6FFKBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP():  \n",
        "  self.input_layer_list = []\n",
        "  self.hidden_layer_list = []\n",
        "  self.output_layer_list = []\n",
        "  \n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def model():\n",
        "    self.weight_matrix = \n",
        "    self.last_layer = None\n",
        "    \n",
        "\n",
        "  def append_layer(layer_type = 'hidden'):\n",
        "    new_layer = Layer('hidden', 3, 'relu')\n",
        "    self.last_layer.connect(new_layer)\n",
        "  \n",
        "  def fit(train_x, train_y):\n",
        "    n_train = 1000000\n",
        "    train_ids = arange(n_train) # [0, 1, .... 99999]\n",
        "    n_epochs = 1000\n",
        "    batch_size = 100\n",
        "    n_batches = n_train // batch_size\n",
        "    hidden_layers = [hidden_layer_1, hidden_layer_2]\n",
        "    for epoch in range(n_epochs):\n",
        "      train_ids = util.shuffle(train_ids)      \n",
        "      for batch_id in range(n_batches):\n",
        "        train_x, train_y = get_data([batch_id:batch_id + batch_size], train_ids)\n",
        "        inp_out = \n",
        "        hidden_1_out = \n",
        "  "
      ],
      "metadata": {
        "id": "Lpbrq9r7Hy0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "6. For each epoch:(for n epochs, where n = len(data) / batch_size):\n",
        "   6.0 . Shuffle training data: ind-array update\n",
        "   For each batch: \n",
        "    6.1. Load train data: [ind: ind + batch_size]\n",
        "    6.2: For each sample:\n",
        "        6.2.0. Forward propogate\n",
        "        6.2.1. Calculate loss for each sample\n",
        "        6.2.2. Backprogate: Calculate gradients and update weights\n",
        "    6.3. Calculate average loss\n",
        "'''\n",
        "n_train = 1000000\n",
        "train_ids = arange(n_train) # [0, 1, .... 99999]\n",
        "n_epochs = 1000\n",
        "batch_size = 100\n",
        "n_batches = n_train // batch_size\n",
        "hidden_layers = [hidden_layer_1, hidden_layer_2]\n",
        "for epoch in range(n_epochs):\n",
        "  train_ids = util.shuffle(train_ids)      \n",
        "  for batch_id in range(n_batches):\n",
        "    train_x, train_y = get_data([batch_id:batch_id + batch_size], train_ids)\n",
        "    inp_out = \n",
        "    hidden_1_out = \n",
        "    "
      ],
      "metadata": {
        "id": "TMr6HrW5DY2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Keras like API\n",
        "* BNN:\n",
        "  * layers\n",
        "    * Dense\n",
        "  * optimizers:\n",
        "    * SGD\n",
        "  * models:\n",
        "    * fit()\n",
        "    * Sequantial:\n",
        "      * predict()\n",
        "      * add()\n",
        "      * compile()\n",
        "* libBNN:\n",
        "  * algos:\n",
        "    * backprop\n",
        "* main.py():\n",
        "  * load_data()\n",
        "  * preprocess_data()\n",
        "  * init_nn()\n",
        "  * model.fit()\n"
      ],
      "metadata": {
        "id": "_NuAz4NMR-Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PR9NEi-yYDdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import libBNN\n",
        "import libData\n",
        "import BNN\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  sum_dataset_df = pd.read_csv('sum_data.csv')\n",
        "  sum_dataset_norm = libData.normalize(sum_dataset_df)\n",
        "  X_train, X_test, Y_train, Y_test = libData.split_train_test(sum_dataset_norm, split_ratio = 0.1)\n",
        "  model = BNN.Sequential() # TODO, #2\n",
        "  model.add(BNN.layers.X) # input layer, #1\n",
        "  model.add(BNN.layers.X) # hidden layer\n",
        "  model.add(BNN.layers.X) # output layer\n",
        "  opt = BNN.optimizers.SGD()\n",
        "  model.compile(opt, loss_fn)\n",
        "  model.fit(X_train, Y_train)\n",
        "\n",
        "  # test predictions\n",
        "  Y_predict = model.predict(X_test)\n",
        "\n",
        "  # evaluate predictions\n",
        "  acc = model.evaluate(Y_predict, Y_test, eval_method)\n",
        "\n",
        "  return\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "566WYofyTi0j",
        "outputId": "a54d1dfe-6405-47e2-ed14-741ea0b6ccb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-beaa1ec1ee8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibBNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libBNN'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}